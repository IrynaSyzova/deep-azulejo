import matplotlib.pyplot as plt
import numpy as np
import math
import torchvision.utils as vutils
import torch.nn
import torch

from src.nn.gan.generator import Generator


def plot_batch(image_batch, plot_size=32, caption=None):
    """
    Plots a grid of images from image_batch
    :param image_batch: Images to plot
    :param plot_size: How many of them; will take first plot_size images
    :param caption: Optional caption for the plot
    """
    plt.figure(figsize=(16, 16))
    plt.axis("off")
    plt.imshow(
        np.transpose(
            vutils.make_grid(
                image_batch[:plot_size].detach().cpu().clamp_(0, 1)[:64], padding=2, normalize=True
            ).cpu(), (1, 2, 0)
        )
    )
    if caption is not None:
        plt.title(caption)

    plt.show()


def new_dim_conv2d_transpose(h_in, kernel_size, stride, dilation=1, padding=0, out_padding=0):
    """
    Helper function I used to define networks structure
    """
    return (h_in-1)*stride - 2*padding + dilation*(kernel_size-1)+out_padding+1


def new_dim_conv2d(h_in, kernel_size, stride, dilation=1, padding=0, out_padding=0):
    """
    Helper function I used to define networks structure
    """
    return math.floor((h_in + 2*padding - dilation*(kernel_size-1)-1)/stride) + 1


def init_weights(layer, std=0.01):
    """
    Weights initiation for networks
    :param layer: layer for which we initiate the weights
    :param std: weight's std
    """
    if isinstance(layer, torch.nn.Conv2d) or \
            isinstance(layer, torch.nn.ConvTranspose2d):
        torch.nn.init.normal_(layer.weight, 0.0, std)
    if isinstance(layer, torch.nn.BatchNorm2d):
        torch.nn.init.normal_(layer.weight, 0.0, std)
        torch.nn.init.constant_(layer.bias, 0)


def save_checkpoint(net, optimiser, path, epoch, loss):
    torch.save({
        'epoch': epoch,
        'model_state_dict': net.state_dict(),
        'optimizer_state_dict': optimiser.state_dict(),
        'loss': loss,
    }, path)


def show_imgs_by_epoch(folder, noise_dim, epochs, n_imgs_show=32):
    """
    Demonstrates training progression by showing a batch of images generated by a generator
    :param folder: path to checkpoints
    :param noise_dim: noise_dim of Generator
    :param epochs: how many epochs is saved
    :param n_imgs_show: how many generated images to show
    """
    path = folder+'/{}_{}.pt'

    losses_generator = []
    losses_critic = []

    for epoch in range(epochs):
        checkpoint_generator = torch.load(path.format('generator', epoch))
        loss = checkpoint_generator['loss']
        losses_generator.append(loss)

        checkpoint_critic = torch.load(path.format('critic', epoch))
        losses_critic.append(checkpoint_critic['loss'])

        generator = Generator(noise_dim)
        generator.load_state_dict(checkpoint_generator['model_state_dict'])
        epoch = checkpoint_generator['epoch']
        generator.eval()

        print('Epoch {}'.format(epoch))
        imgs = generator(generator.get_noise(n_imgs_show))
        plot_batch(imgs)

    plt.plot(losses_generator, label='generator')
    plt.plot(losses_critic, label='critic')
    plt.legend()
